{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13320a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from climada.hazard import TCTracks\n",
    "import numpy as np\n",
    "\n",
    "# os.chdir('C:/Users/EB735DB/climada_workspace/')\n",
    "import dill\n",
    "# filepath = 'Historical typhoon_China_51tracks.pkl'\n",
    "# dill.load_session(filepath)\n",
    "import cartopy.crs as ccrs\n",
    "import shapely\n",
    "import time\n",
    "from cartopy.io import shapereader\n",
    "from climada.hazard import Centroids, TropCyclone\n",
    "\n",
    "filepath_output = 'eai_51tracks_China.pkl'\n",
    "\n",
    "csv_output = 'impact_China_51tracks.csv'\n",
    "\n",
    "v_half_wp1 = 80.2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449af43",
   "metadata": {},
   "source": [
    "###### step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load cyclones from cma provider\n",
    "sel_ibtracs = TCTracks.from_ibtracs_netcdf(provider = 'cma',year_range=(1960,2022), correct_pres=False)\n",
    "print('Number of tracks:', sel_ibtracs.size)\n",
    "storm_num = sel_ibtracs.size\n",
    "sel_ibtracs_raw = sel_ibtracs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulate syntheic tracks\n",
    "from pathos.pools import ProcessPool as Pool\n",
    "pool = Pool() # start a pathos pool\n",
    "sel_ibtracs.equal_timestep(0.5,pool=pool)  # Interpolation to make the track smooth and to allow applying calc_perturbed_trajectories\n",
    "# Add randomly generated tracks using the calc_perturbed_trajectories method (1 per historical track)\n",
    "sel_ibtracs.calc_perturbed_trajectories(nb_synth_tracks=50,pool=pool)\n",
    "print('num tracks hist+syn:', sel_ibtracs.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e404b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15c4a3a9",
   "metadata": {},
   "source": [
    "###### step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdab157",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_file = 'C:/Users/CZ551FU/climada_workspace/Datasets/China_Aliyun/China.shp'\n",
    "\"\"\"initiate LitPop exposures for a geographical box around China:\"\"\"\n",
    "reader = shapereader.Reader(shp_file) # read shpfile of China\n",
    "# LOGGER.info(\"Computing earth's land geometry ...\")\n",
    "geom = list(reader.geometries())\n",
    "geom_new = []\n",
    "for i in range(len(geom)):\n",
    "    geom_new.append(geom[i].buffer(0.01))\n",
    "geom_new = shapely.ops.unary_union(geom_new)\n",
    "\n",
    "from climada.entity import LitPop\n",
    "total_value=1\n",
    "# exp_lp = LitPop.from_countries(countries=['HK'], res_arcsec=30, fin_mode='income_group')\n",
    "exp_lp = LitPop.from_shape(geom_new, total_value, res_arcsec=360) # rougly 1km\n",
    "exp_lp.check()\n",
    "exp_lp.gdf.value = 1\n",
    "exp_lp.gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f395a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### only slics longitude\n",
    "z = 0 + 1\n",
    "min_lat, max_lat, min_lon, max_lon = exp_lp.gdf.latitude.min() - 0.1,exp_lp.gdf.latitude.max() + 0.1,exp_lp.gdf.longitude.min() - 0.1,exp_lp.gdf.longitude.max() + 0.1\n",
    "d = {}\n",
    "for y in range(1,63):\n",
    "    d[\"min_lat{0}\".format(z)] = min_lat \n",
    "    d[\"max_lat{0}\".format(z)] = max_lat\n",
    "    if y == 62:\n",
    "        d[\"min_lat{0}\".format(z)] = min_lat \n",
    "        d[\"max_lat{0}\".format(z)] = max_lat \n",
    "        d[\"min_lon{0}\".format(z)] = min_lon + (y-1) * 1\n",
    "        d[\"max_lon{0}\".format(z)] = max_lon        \n",
    "    else:\n",
    "        d[\"min_lon{0}\".format(z)] = min_lon + (y-1) * 1\n",
    "        d[\"max_lon{0}\".format(z)] = min_lon + (y) * 1\n",
    "    z = z + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cent\n",
    "from climada.hazard import Centroids, TropCyclone\n",
    "cent_dict = {}\n",
    "for i in range(1,int(len(d)/4)):\n",
    "    cent_dict['cent{}'.format(i)] = Centroids.from_pnt_bounds((d['min_lon{}'.format(i)], d['min_lat{}'.format(i)], d['max_lon{}'.format(i)], d['max_lat{}'.format(i)]), res=0.1) #~11.1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ff8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the cyclone tracks\n",
    "tc_dict = {}\n",
    "for i in range(1,int(len(d)/4)):\n",
    "    tc_dict['tc_{}'.format(i)] = TropCyclone.from_tracks(sel_ibtracs, centroids=cent_dict['cent{}'.format(i)],pool=pool)\n",
    "    print('finished tc{}'.format(i) + str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a8649e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new(lst, *others):\n",
    "\n",
    "    # pylint: disable=no-member, protected-access\n",
    "    if len(others) == 0:\n",
    "        return\n",
    "    haz_list = [lst] + list(others)\n",
    "    haz_list_nonempty = [haz for haz in haz_list if haz.size > 0]\n",
    "\n",
    "#     for haz in haz_list:\n",
    "#         haz._check_events()\n",
    "\n",
    "    # check type, unit, and attribute consistency among hazards\n",
    "    haz_types = {haz.tag.haz_type for haz in haz_list if haz.tag.haz_type != ''}\n",
    "    if len(haz_types) > 1:\n",
    "        raise ValueError(f\"The given hazards are of different types: {haz_types}. \"\n",
    "                         \"The hazards are incompatible and cannot be concatenated.\")\n",
    "    lst.tag.haz_type = haz_types.pop()\n",
    "\n",
    "    haz_classes = {type(haz) for haz in haz_list}\n",
    "    if len(haz_classes) > 1:\n",
    "        raise TypeError(f\"The given hazards are of different classes: {haz_classes}. \"\n",
    "                        \"The hazards are incompatible and cannot be concatenated.\")\n",
    "\n",
    "    units = {haz.units for haz in haz_list if haz.units != ''}\n",
    "    if len(units) > 1:\n",
    "        raise ValueError(f\"The given hazards use different units: {units}. \"\n",
    "                         \"The hazards are incompatible and cannot be concatenated.\")\n",
    "    if len(units) == 0:\n",
    "        units = {''}\n",
    "    lst.units = units.pop()\n",
    "\n",
    "    attributes = sorted(set.union(*[set(vars(haz).keys()) for haz in haz_list]))\n",
    "    for attr_name in attributes:\n",
    "        if not all(hasattr(haz, attr_name) for haz in haz_list_nonempty):\n",
    "            raise ValueError(f\"Attribute {attr_name} is not shared by all hazards. \"\n",
    "                             \"The hazards are incompatible and cannot be concatenated.\")\n",
    "\n",
    "    # append all tags (to keep track of input files and descriptions)\n",
    "    for haz in haz_list:\n",
    "        if haz.tag is not lst.tag:\n",
    "            lst.tag.append(haz.tag)\n",
    "\n",
    "    # map individual centroids objects to union\n",
    "    centroids = Centroids.union(*[haz.centroids for haz in haz_list])\n",
    "    hazcent_in_cent_idx_list = [\n",
    "        u_coord.assign_coordinates(haz.centroids.coord, centroids.coord, threshold=0)\n",
    "        for haz in haz_list_nonempty\n",
    "    ]\n",
    "\n",
    "    # concatenate array and list attributes of non-empty hazards\n",
    "    for attr_name in attributes:\n",
    "        attr_val_list = [getattr(haz, attr_name) for haz in haz_list_nonempty]\n",
    "        if isinstance(attr_val_list[0], sparse.csr.csr_matrix):\n",
    "            # map sparse matrix onto centroids\n",
    "            setattr(lst, attr_name, sparse.vstack([\n",
    "                sparse.csr_matrix(\n",
    "                    (matrix.data, cent_idx[matrix.indices], matrix.indptr),\n",
    "                    shape=(matrix.shape[0], centroids.size)\n",
    "                )\n",
    "                for matrix, cent_idx in zip(attr_val_list, hazcent_in_cent_idx_list)\n",
    "            ], format='csr'))\n",
    "        elif isinstance(attr_val_list[0], np.ndarray) and attr_val_list[0].ndim == 1:\n",
    "            setattr(lst, attr_name, np.hstack(attr_val_list))\n",
    "        elif isinstance(attr_val_list[0], list):\n",
    "            setattr(lst, attr_name, sum(attr_val_list, []))\n",
    "\n",
    "    lst.centroids = centroids\n",
    "    lst.sanitize_event_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd684718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climada.util.coordinates as u_coord\n",
    "from scipy import sparse\n",
    "for i in range(1,int(len(d)/4)):\n",
    "    print(i)\n",
    "    append_new(tc_dict['tc_1'],tc_dict['tc_{}'.format(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba765425",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_dict['tc_1'].plot_intensity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tc.check()\n",
    "for haz in [tc_dict['tc_1']]:\n",
    "    print(len(haz.event_id))\n",
    "    print(len(haz._events_set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e1bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set up impact function\"\"\"\n",
    "from climada.entity import ImpactFuncSet, ImpfTropCyclone\n",
    "# impact function TC\n",
    "impf_tc = ImpfTropCyclone.from_emanuel_usa(v_half=v_half_wp1) # WP1\n",
    "\n",
    "# add the impact function to an Impact function set\n",
    "impf_set = ImpactFuncSet()\n",
    "impf_set.append(impf_tc)\n",
    "impf_set.check()\n",
    " \n",
    "# Get the hazard type and hazard id\n",
    "[haz_type] = impf_set.get_hazard_types()\n",
    "[haz_id] = impf_set.get_ids()[haz_type]\n",
    "#print(f\"hazard type: {haz_type}, hazard id: {haz_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.engine import Impact\n",
    "imp = Impact()\n",
    "imp.calc(exp_lp, impf_set, tc_dict['tc_1'], save_mat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.unit = \"unitless\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.plot_scatter_eai_exposure(ignore_zero=False, buffer=0.03);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28921527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data={\n",
    "    'value': imp.eai_exp,\n",
    "    'latitude': imp.coord_exp[:, 0],\n",
    "    'longitude': imp.coord_exp[:, 1],\n",
    "}\n",
    "imp_data = pd.DataFrame(data)\n",
    "#imp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The centroid has max windspeed\n",
    "max_cent = imp_data.iloc[imp_data[['value']].idxmax()[0]]\n",
    "max_cent_lat = max_cent.latitude\n",
    "max_cent_lon = max_cent.longitude\n",
    "max_cent_eai = max_cent.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Eai_mean\",np.mean(imp.eai_exp),\n",
    "      \"Eai_max\",max_cent_eai,\"where is at\", max_cent_lat, max_cent_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad065dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_output = 'impact_China_51tracks.csv'\n",
    "imp_data.to_csv(csv_output,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session(filepath_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
